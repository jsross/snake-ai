# Snake AI Jupyter Notebooks

This directory contains Jupyter notebooks for analyzing and experimenting with the Snake AI project. These notebooks provide interactive tools for data analysis, model evaluation, and hyperparameter optimization.

## üìö Available Notebooks

### 1. `training_analysis.ipynb`
**Comprehensive Training Data Analysis**
- Load and visualize training data from CSV files
- Compare performance across different strategies
- Analyze reward components and their effectiveness
- Create interactive dashboards with training metrics
- Export analysis results for reporting

**Key Features:**
- Automatic data loading from project directories
- Rolling average calculations and trend analysis
- Strategy comparison visualizations
- Performance metrics dashboard
- Correlation analysis of reward components

### 2. `model_evaluation.ipynb`
**Model Testing and Performance Evaluation**
- Load and test trained models interactively
- Evaluate model performance across multiple games
- Analyze model decision-making patterns
- Compare different model versions
- Visualize model behavior and confidence

**Key Features:**
- Automated model discovery and loading
- Comprehensive performance testing
- Decision analysis and visualization
- Safety and risk assessment
- Model comparison tools

### 3. `hyperparameter_experiments.ipynb`
**Interactive Hyperparameter Optimization**
- Experiment with learning rates, reward weights, and epsilon strategies
- Test custom reward functions
- Visualize parameter sensitivity
- Run quick training experiments
- Generate optimal configuration recommendations

**Key Features:**
- Systematic parameter exploration
- Custom reward function prototyping
- 3D visualization of parameter spaces
- Performance comparison tools
- Automated configuration optimization

## üöÄ Getting Started

### Prerequisites
Make sure you have the following packages installed:
```bash
pip install jupyter ipykernel matplotlib seaborn plotly pandas
```

### Running the Notebooks

1. **Start Jupyter Lab/Notebook:**
   ```bash
   # From the project root directory
   cd notebooks
   jupyter lab
   # or
   jupyter notebook
   ```

2. **Open any notebook** and run the cells sequentially

3. **Adjust paths if needed** - The notebooks automatically look for data in the standard project locations, but you may need to adjust paths based on your setup.

## üìä Data Sources

The notebooks work with data generated by your Snake AI training sessions:

- **Training Data**: CSV files in `%APPDATA%/SnakeAI/[ProjectName]/logs/`
- **Model Files**: `.pth` files in `%APPDATA%/SnakeAI/[ProjectName]/models/`
- **Configuration**: YAML files in the `config/` directory

## üîß Customization

### Adding Custom Analysis
You can extend the notebooks by:
- Adding new visualization functions
- Implementing custom metrics
- Creating new experimental designs
- Integrating with external tools (TensorBoard, Weights & Biases)

### Example: Adding a Custom Metric
```python
def calculate_efficiency_metric(df):
    \"\"\"Calculate a custom efficiency metric.\"\"\"
    return df['score'] / df['steps']

# Add to your analysis
df['efficiency'] = calculate_efficiency_metric(df)
```

## üìà Integration with Main Project

### Using Analysis Results
The notebooks can export results that integrate back into your main project:
- Optimal hyperparameter configurations (JSON)
- Performance benchmarks (CSV)
- Analysis reports (Markdown)

### Example Integration
```python
# Load optimal hyperparameters found in notebooks
with open('../hyperparameter_experiments/optimal_hyperparameters_20250818_120000.json') as f:
    optimal_config = json.load(f)

# Use in your training script
learning_rate = optimal_config['learning_rate']
reward_weights = optimal_config['reward_weights']
```

## üéØ Common Use Cases

### 1. **Post-Training Analysis**
After running training sessions, use `training_analysis.ipynb` to:
- Understand training progress and convergence
- Identify the most effective strategies
- Analyze reward component contributions
- Generate performance reports

### 2. **Model Evaluation**
Before deploying models, use `model_evaluation.ipynb` to:
- Test model performance across multiple scenarios
- Analyze decision-making patterns
- Compare different model versions
- Validate model safety and reliability

### 3. **Hyperparameter Optimization**
Before starting long training runs, use `hyperparameter_experiments.ipynb` to:
- Find optimal learning rates and reward weights
- Test different exploration strategies
- Prototype new reward functions
- Optimize training efficiency

### 4. **Research and Development**
For experimenting with new ideas:
- Prototype new training strategies
- Test different game configurations
- Analyze the impact of architectural changes
- Develop new evaluation metrics

## üõ†Ô∏è Troubleshooting

### Common Issues

1. **"No training data found"**
   - Ensure you've run training sessions that generate CSV files
   - Check the data path in the notebook cells
   - Verify project data is in the expected location

2. **"Module import errors"**
   - Make sure you're running notebooks from the correct directory
   - Check that the `src` directory is properly added to the Python path
   - Verify all required packages are installed

3. **"Empty visualizations"**
   - Ensure your training data contains the expected columns
   - Check for sufficient data points (at least 50-100 episodes)
   - Verify data is not corrupted or empty

### Performance Tips

1. **For large datasets**, consider:
   - Loading only recent data using date filters
   - Sampling data for visualization
   - Using rolling averages to reduce noise

2. **For quick experiments**, adjust:
   - Reduce the number of episodes in hyperparameter experiments
   - Use smaller parameter ranges for initial exploration
   - Run experiments in parallel where possible

## üìù Contributing

To add new notebooks or improve existing ones:

1. Follow the established structure and naming conventions
2. Include comprehensive documentation and comments
3. Test with different data scenarios
4. Add error handling for common edge cases
5. Include example outputs and visualizations

## üîó Related Documentation

- [Main Project README](../README.md)
- [Configuration System](../docs/CONFIG_SYSTEM.md)
- [Training Framework](../docs/TRAINING_FRAMEWORK.md)
- [Strategy Selection Guide](../docs/STRATEGY_SELECTION_GUIDE.md)

## üìß Support

If you encounter issues or have questions about the notebooks:
1. Check the troubleshooting section above
2. Review the main project documentation
3. Look at the example outputs in each notebook
4. Consider the notebook's assumptions about data structure and format
